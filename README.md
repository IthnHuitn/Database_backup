# Домашнее задание к занятию "`Резервное копирование баз данных`" - `Ефимов Вячеслав`


### Инструкция по выполнению домашнего задания

   1. Сделайте `fork` данного репозитория к себе в Github и переименуйте его по названию или номеру занятия, например, https://github.com/имя-вашего-репозитория/git-hw или  https://github.com/имя-вашего-репозитория/7-1-ansible-hw).
   2. Выполните клонирование данного репозитория к себе на ПК с помощью команды `git clone`.
   3. Выполните домашнее задание и заполните у себя локально этот файл README.md:
      - впишите вверху название занятия и вашу фамилию и имя
      - в каждом задании добавьте решение в требуемом виде (текст/код/скриншоты/ссылка)
      - для корректного добавления скриншотов воспользуйтесь [инструкцией "Как вставить скриншот в шаблон с решением](https://github.com/netology-code/sys-pattern-homework/blob/main/screen-instruction.md)
      - при оформлении используйте возможности языка разметки md (коротко об этом можно посмотреть в [инструкции  по MarkDown](https://github.com/netology-code/sys-pattern-homework/blob/main/md-instruction.md))
   4. После завершения работы над домашним заданием сделайте коммит (`git commit -m "comment"`) и отправьте его на Github (`git push origin`);
   5. Для проверки домашнего задания преподавателем в личном кабинете прикрепите и отправьте ссылку на решение в виде md-файла в вашем Github.
   6. Любые вопросы по выполнению заданий спрашивайте в чате учебной группы и/или в разделе “Вопросы по заданию” в личном кабинете.
   
Желаем успехов в выполнении домашнего задания!
   
### Дополнительные материалы, которые могут быть полезны для выполнения задания

1. [Руководство по оформлению Markdown файлов](https://gist.github.com/Jekins/2bf2d0638163f1294637#Code)

---

### Задание 1

#### 1.1. Восстановление данных в полном объёме за предыдущий 

- Подходящий вариант: Ежедневное полное (Full) резервное копирование.

- Что это: Создание полной копии всей базы данных на момент окончания рабочего дня.

- Почему подходит: Процесс восстановления максимально прост и быстр — 
требуется развернуть только один резервный набор (бекап) за нужный день. 
Это обеспечивает именно тот уровень согласованности данных, 
который требуется — "состояние на конец предыдущего дня".

- Недостатки для этого кейса: При большом объёме данных полный бэкап может 
занимать много времени и ресурсов. Однако, поскольку требование — "за предыдущий день", 
а не "за последний час", этот метод идеально соответствует задаче.

- Практическая реализация: Бэкап запускается каждый день после окончания основных операций, 
например, в 23:00. Хранится несколько последних копий (на неделю или месяц).

#### 1.2. Восстановление данных за час до предполагаемой поломки

- Подходящий вариант: Комбинация полных и инкрементальных/дифференциальных копий, 
дополненная резервным копированием журналов транзакций (Transaction Log Backup).

- Для восстановления на произвольный момент времени (Point-in-Time Recovery) 
с точностью до часа необходима более сложная стратегия:

- Полный бэкап (Foundation): Выполняется, например, раз в неделю по воскресеньям. 
Это основа для восстановления.

- Инкрементальный (Incremental) или дифференциальный (Differential) бэкап: Выполняется ежедневно. 
Инкрементальный сохраняет изменения с последнего любого бэкапа, дифференциальный — с последнего полного. 
Это ускоряет ежедневное резервирование по сравнению с полным бэкапом.

- Ключевой элемент — Резервное копирование журналов транзакций (Transaction Log Backup): 
Выполняется каждые 30-60 минут. Журнал транзакций фиксирует все изменения в базе. 
Цепочка таких журналов позволяет "накатить" на последнюю полную+дифференциальную копию все транзакции, 
совершенные вплоть до конкретного момента времени.

##### Процесс восстановления в данном кейсе:

- Восстановить последний полный бэкап.

- Восстановить последний дифференциальный бэкап (если используется).

- Последовательно применить (восстановить) все резервные копии журналов транзакций, 
созданные после этого, остановившись на момоде "за час до поломки".

- Эта стратегия обеспечивает минимальную потерю данных (RPO ~1 час).

#### 1.3.* Моментальное переключение при поломке

Да, такой кейс возможен. Это реализуется решениями высокой доступности (High Availability, HA) 
и аварийного переключения (Disaster Recovery, DR).

Механизмы, обеспечивающие "моментальное" (на самом деле от нескольких секунд до минуты) переключение:

1. Репликация баз данных:

- Always On Availability Groups (SQL Server), Oracle Data Guard, Streaming Replication (PostgreSQL): 
Данные синхронно или асинхронно реплицируются с основного сервера (Primary) 
на один или несколько вторичных (Secondary). При отказе основного автоматически или 
вручную происходит переключение (failover) на вторичную реплику, 
которая становится новой основной базой. Для пользователей и приложений 
это выглядит как кратковременный сбой в соединении.

2. Кластеризация отказоустойчивости (Failover Clustering):

- Общее хранилище данных (SAN) используется несколькими узлами кластера. 
При падении активного узла кластер перезапускает службы СУБД на резервном узле, 
используя те же самые данные на диске. Переключение происходит быстро, 
но обычно требует общего хранилища, что является "единой точкой отказа".

3. Автоматическое восстановление с помощью резервных копий:

- Не является "моментальным" в прямом смысле, но может быть автоматизировано. 
Некоторые облачные и хостинговые решения (например, AWS RDS) позволяют автоматически 
создать новую инстанс базы данных из последней резервной копии в случае падения основной. 
Это занимает минуты или десятки минут, что для многих бизнес-процессов также приемлемо 
как "быстрое восстановление".

- Вывод для 1.3: Для моментального переключения используется не просто резервное копирование, 
а технологии репликации в реальном времени. Резервные копии в этом случае остаются 
важнейшим элементом защиты от логических ошибок (например, если ошибочная 
команда DELETE реплицируется на standby-сервер, нужна именно резервная копия, чтобы откатиться).

#### Итоговая рекомендация для компании:

- Для баланса надёжности, скорости восстановления и стоимости рекомендуется комбинированная стратегия:

- Для целей быстрого восстановления на произвольный момент (RPO ~15-60 мин): 
Использовать полные бэкапы еженедельно + дифференциальные ежедневно + копирование журналов транзакций 
каждые 15-60 минут.

- Для обеспечения высокой доступности и мгновенного переключения при сбое железа или ОС: 
Развернуть синхронную репликацию на standby-сервер в том же дата-центре (HA).

- Для защиты от катастрофы в дата-центре: Настроить асинхронную репликацию в удалённый дата-центр 
или облако (DR) и регулярно выгружать полные резервные копии в объектное хранилище с другой географией.

- Регулярно проводить учения по восстановлению из резервных копий, чтобы проверить их целостность и отработать процедуры.


---

### Задание 2

#### 2.1. Примеры команд резервного копирования и восстановления в PostgreSQL

- Резервное копирование с помощью pg_dump

1. Резервное копирование всей базы данных в файл:

```bash
pg_dump -U username -d database_name -f backup.sql
```

2. Резервное копирование в сжатый формат с собственным (custom) форматом PostgreSQL:

```bash
pg_dump -U username -d database_name -F c -f backup.dump
```

- -F c — формат вывода "custom" (сжатый, поддерживает параллельное восстановление)

- Такой формат может быть восстановлен только через pg_restore

3. Резервное копирование с детализацией:

```bash
pg_dump -U username -h localhost -p 5432 -d mydatabase \
  --clean --create --verbose --compress=9 \
  --file=mydatabase_backup_$(date +%Y%m%d).dump \
  --format=c
  ```

- --clean — добавляет команды DROP перед CREATE (удобно для полного пересоздания)

- --create — включает команду CREATE DATABASE

- --verbose — подробный вывод процесса

- --compress=9 — уровень сжатия (0-9)

- $(date +%Y%m%d) — добавляет дату к имени файла

4. Резервное копирование только схемы (без данных):

```bash
pg_dump -U username -d database_name --schema-only -f schema.sql
```

5. Резервное копирование только данных:

```bash
pg_dump -U username -d database_name --data-only -f data.sql
```

- Восстановление с помощью pg_restore

1. Восстановление из custom-формата:

```bash
pg_restore -U username -d database_name backup.dump
```

2. Восстановление в новую базу данных:

```bash
# Сначала создаем базу данных
createdb -U username new_database

# Восстанавливаем в нее
pg_restore -U username -d new_database backup.dump
```

3. Восстановление только структуры:

```bash
pg_restore -U username -d database_name --schema-only backup.dump
```

4. Восстановление с параллельным выполнением (ускоряет процесс):

```bash
pg_restore -U username -d database_name -j 4 backup.dump
```

- -j 4 — использует 4 параллельных потока

5. Восстановление из обычного SQL-файла:

```bash
psql -U username -d database_name -f backup.sql
```

#### 2.1.* Автоматизация процесса резервного копирования
- Да, автоматизировать процесс резервного копирования возможно и обязательно для production-среды.

1. Скрипты + планировщик заданий (cron)
Пример bash-скрипта для автоматического резервного копирования:

```bash
#!/bin/bash
# backup_postgres.sh

# Настройки
BACKUP_DIR="/var/backups/postgres"
DATE=$(date +%Y%m%d_%H%M%S)
DB_NAME="my_database"
USERNAME="postgres"
RETENTION_DAYS=7

# Создаем директорию для бэкапов, если её нет
mkdir -p $BACKUP_DIR

# Имя файла бэкапа
BACKUP_FILE="$BACKUP_DIR/${DB_NAME}_${DATE}.dump"

# Выполняем резервное копирование
echo "Начало резервного копирования $DB_NAME в $BACKUP_FILE"
pg_dump -U $USERNAME -d $DB_NAME -F c -f $BACKUP_FILE

# Проверяем успешность выполнения
if [ $? -eq 0 ]; then
    echo "Резервное копирование успешно завершено"
    
    # Удаляем старые бэкапы (старше RETENTION_DAYS дней)
    find $BACKUP_DIR -name "${DB_NAME}_*.dump" -mtime +$RETENTION_DAYS -delete
    echo "Удалены бэкапы старше $RETENTION_DAYS дней"
else
    echo "Ошибка при резервном копировании!"
    exit 1
fi
```

- Добавление в cron для ежедневного выполнения в 2:00:

```bash
0 2 * * * /path/to/backup_postgres.sh >> /var/log/postgres_backup.log 2>&1
```

2. Использование pgBackRest или Barman

- pgBackRest — профессиональное решение для резервного копирования PostgreSQL:

```bash
# Установка и настройка pgBackRest
# Конфигурационный файл /etc/pgbackrest.conf
[global]
repo1-path=/var/lib/pgbackrest
repo1-retention-full=2

[mycluster]
pg1-path=/var/lib/postgresql/16/main

# Создание полного бэкапа
pgbackrest --stanza=mycluster backup --type=full

# Автоматизация через cron
0 1 * * * pgbackrest --stanza=mycluster --type=incr backup
```

- Barman (Backup and Recovery Manager) — еще одно популярное решение:

```bash
# Резервное копирование
barman backup myserver

# Автоматическое управление ретеншеном
barman cron
```

3. Интеграция с облачными хранилищами
- Автоматическая выгрузка бэкапов в облако:

```bash
#!/bin/bash
# Создаем локальный бэкап
pg_dump -U postgres -d mydb -F c -f /tmp/backup.dump

# Загружаем в облако (пример для AWS S3)
aws s3 cp /tmp/backup.dump s3://my-backup-bucket/postgres/$(date +%Y%m%d).dump

# Очистка временных файлов
rm /tmp/backup.dump
```

4. Использование репликации + WAL-архивирование для Point-in-Time Recovery
- Настройка непрерывного архивирования WAL:

`postgresql`
```postgresql
# В postgresql.conf
wal_level = replica
archive_mode = on
archive_command = 'cp %p /var/lib/postgresql/wal_archive/%f'
```

- Автоматический скрипт для PITR:

```bash
#!/bin/bash
# Автоматическое создание базовых бэкапов
BASE_BACKUP_DIR="/backups/base"
WAL_ARCHIVE_DIR="/backups/wal"

# Создаем базовый бэкап
pg_basebackup -D $BASE_BACKUP_DIR/$(date +%Y%m%d) -X fetch

# Архивируем WAL-файлы
find $WAL_ARCHIVE_DIR -name "*.backup" -mtime +30 -delete
```

#### Рекомендации по автоматизации:

1. Регулярное тестирование восстановления — минимум раз в квартал проверять, 
что бэкапы действительно восстанавливаются.

2. Многоуровневое хранение — хранить бэкапы в разных местах 
(локально, в облаке, в нескольких географических локациях ).

3. Ведение журналов — логировать все операции резервного копирования
 и восстановления.

4. Мониторинг — настроить алерты при пропуске бэкапов или ошибках.

5. Шифрование — шифровать бэкапы, особенно при хранении в облаке 
или выносе за пределы защищенного периметра.

#### Автоматизация резервного копирования PostgreSQL — это не просто удобство, а необходимое условие для обеспечения отказоустойчивости и соответствия требованиям бизнеса по доступности данных.


### Задание 3

#### 3.1. Инкрементное резервное копирование в MySQL

- В MySQL инкрементное резервное копирование тесно связано с бинарным логом (binary log). 
Бинарный лог содержит все изменения данных (операторы DML и DDL), 
которые можно использовать для восстановления базы до определенного момента времени.

- Предварительные требования
1. Включить бинарный лог и задать уникальный server-id:

```ini
# В файле my.cnf или my.ini
[mysqld]
server-id = 1
log-bin = /var/log/mysql/mysql-bin.log
binlog_format = ROW  # или MIXED
```

2. Перезапустить MySQL сервер:

```bash
sudo systemctl restart mysql
```

#### Процесс инкрементного резервного копирования

 - Шаг 1: Создание полной резервной копии (фулбэкапа)

```bash
# Блокируем таблицы на запись для согласованности данных
mysql -u root -p -e "FLUSH TABLES WITH READ LOCK;"

# Получаем текущую позицию в бинарном логе
mysql -u root -p -e "SHOW MASTER STATUS" > /backups/master_status.txt

# Создаем полную резервную копию
mysqldump -u root -p --all-databases --master-data=2 --single-transaction \
  --flush-logs --triggers --routines --events \
  > /backups/full_backup_$(date +%Y%m%d).sql

# Разблокируем таблицы
mysql -u root -p -e "UNLOCK TABLES;"
```

- Шаг 2: Создание инкрементных резервных копий

```bash
# Принудительно ротируем бинарный лог (создаем новый файл)
mysqladmin -u root -p flush-logs

# Копируем предыдущий бинарный лог (текущий минус один)
# Находим последний использованный бинарный лог
LAST_BINLOG=$(ls -t /var/log/mysql/mysql-bin.* | head -2 | tail -1)

# Копируем его как инкрементный бэкап
cp $LAST_BINLOG /backups/incremental/$(date +%Y%m%d_%H%M%S)_binlog_backup
```

#### Автоматизированный скрипт для инкрементного бэкапа

```bash
#!/bin/bash
# incremental_mysql_backup.sh

# Конфигурация
BACKUP_DIR="/backups/mysql"
INCREMENTAL_DIR="$BACKUP_DIR/incremental"
MYSQL_USER="backup_user"
MYSQL_PASSWORD="secure_password"
LOG_FILE="/var/log/mysql_backup.log"

# Создаем директории если не существуют
mkdir -p $INCREMENTAL_DIR

# Получаем список бинарных логов
BINLOGS=$(mysql -u$MYSQL_USER -p$MYSQL_PASSWORD -e "SHOW BINARY LOGS;" | tail -n +2 | awk '{print $1}')

# Для каждого бинарного лога (кроме текущего активного)
for binlog in $BINLOGS; do
    # Проверяем, не является ли это текущим активным логом
    CURRENT_LOG=$(mysql -u$MYSQL_USER -p$MYSQL_PASSWORD -e "SHOW MASTER STATUS\G" | grep "File:" | awk '{print $2}')
    
    if [ "$binlog" != "$CURRENT_LOG" ]; then
        # Проверяем, не скопировали ли мы уже этот файл
        if [ ! -f "$INCREMENTAL_DIR/$binlog" ]; then
            echo "$(date): Копируем бинарный лог $binlog" >> $LOG_FILE
            # Используем mysqlbinlog для получения человекочитаемого формата
            mysqlbinlog /var/log/mysql/$binlog > $INCREMENTAL_DIR/${binlog}.txt
            # Или копируем сам бинарный файл
            cp /var/log/mysql/$binlog $INCREMENTAL_DIR/
        fi
    fi
done

# Очищаем старые бинарные логи (после того как скопировали)
mysql -u$MYSQL_USER -p$MYSQL_PASSWORD -e "PURGE BINARY LOGS BEFORE DATE_SUB(NOW(), INTERVAL 7 DAY);"

echo "$(date): Инкрементное резервное копирование завершено" >> $LOG_FILE
```

#### Восстановление из инкрементных резервных копий

- Процесс восстановления:

```bash
# 1. Восстанавливаем полный бэкап
mysql -u root -p < /backups/full_backup_20240101.sql

# 2. Применяем инкрементные изменения из бинарных логов
# Находим позицию, с которой нужно начать
START_POSITION=$(grep "CHANGE MASTER TO" /backups/full_backup_20240101.sql | head -1)

# Применяем все инкрементные бэкапы по порядку
for binlog in $(ls /backups/incremental/mysql-bin.* | sort); do
    mysqlbinlog $binlog | mysql -u root -p
done

# 3. Или восстанавливаем до определенного момента времени
mysqlbinlog \
  --start-datetime="2024-01-15 10:00:00" \
  --stop-datetime="2024-01-15 11:00:00" \
  /var/log/mysql/mysql-bin.* | mysql -u root -p
```

#### Использование Percona XtraBackup для инкрементного бэкапа

- Percona XtraBackup — популярное решение для физического резервного копирования MySQL:

```bash
# Полный бэкап
xtrabackup --backup --target-dir=/backups/full --user=backup_user --password=password

# Первый инкрементный бэкап (относительно полного)
xtrabackup --backup \
  --target-dir=/backups/inc1 \
  --incremental-basedir=/backups/full \
  --user=backup_user --password=password

# Второй инкрементный бэкап (относительно предыдущего инкрементного)
xtrabackup --backup \
  --target-dir=/backups/inc2 \
  --incremental-basedir=/backups/inc1 \
  --user=backup_user --password=password

# Восстановление
xtrabackup --prepare --apply-log-only --target-dir=/backups/full
xtrabackup --prepare --apply-log-only --target-dir=/backups/full --incremental-dir=/backups/inc1
xtrabackup --prepare --apply-log-only --target-dir=/backups/full --incremental-dir=/backups/inc2
xtrabackup --prepare --target-dir=/backups/full
```

#### 3.1.* Преимущества реплики по сравнению с обычным резервным копированием

- Репликация в MySQL предлагает несколько ключевых преимуществ перед традиционным резервным копированием:

1. Нулевое время восстановления (или близкое к нулю)

- Реплика: При падении мастера можно мгновенно (секунды) переключиться на реплику

- Бэкап: Восстановление из бэкапа может занимать часы на больших базах данных

2. Минимальная потеря данных (RPO)

- Синхронная/полусинхронная реплика: Потеря данных = 0 или несколько секунд

- Асинхронная реплика: Обычно отставание несколько секунд-минут

- Бэкап: Потеря данных от 1 часа (при ежечасном бэкапе) до 24 часов (при ежедневном)

3. Тестирование без воздействия на продакшен

- Реплика: Можно использовать для:

- Тестирования обновлений

- Запуска тяжелых аналитических запросов

- Проверки производительности

- Бэкап: Для тестирования нужно восстановить копию, что занимает время и ресурсы

4. Географическое распределение и отказоустойчивость

- Реплика: Можно разместить в другом дата-центре/регионе

- Бэкап: Требуется физическая транспортировка или медленная загрузка из облака

5. Масштабирование чтения

- Реплика: Можно направлять read-запросы на реплики, разгружая мастер

- Бэкап: Не помогает с масштабированием нагрузки

6. Непрерывная доступность при обслуживании

- Реплика: Можно выводить мастер на обслуживание, временно переключая на реплику

- Бэкап: Требует остановки сервиса на время восстановления

7. Защита от человеческих ошибок

- Реплика: Можно настроить задержку репликации (delayed replication), например, на 1 час

- Если на мастере ошибочно удалили данные, есть час чтобы это обнаружить и остановить репликацию

- Бэкап: Нужно восстанавливать всю базу, что может быть долго

8. Упрощенное бэкапирование

- Реплика: Можно делать бэкапы с реплики, не нагружая мастер

- Бэкап мастера: Создает нагрузку и может влиять на производительность

9. Точка восстановления в реальном времени

-Реплика: Можно остановить репликацию в любой момент для создания согласованного снапшота

- Бэкап: Согласованность только на момент начала бэкапа

10. Мониторинг и диагностика

- Реплика: Lag (отставание) реплики — хороший индикатор здоровья системы

- Бэкап: Только факт успешного/неуспешного завершения

### Когда реплика НЕ заменяет бэкап:

1. Логические ошибки: Если ошибочный DELETE выполнен на мастере, 
он реплицируется на все реплики

2. Физическая порча данных: Битая файловая система может повредить и мастер, и реплику

3. Юридические требования: Некоторые стандарты требуют offline-хранилища бэкапов

4. Долгосрочное хранение: Реплики хранят только текущие данные, а не исторические снимки

5. Версионирование: Невозможно восстановить данные 30-дневной давности из реплики

### Золотое правило:

#### Репликация — для высокой доступности и масштабирования.

#### Резервное копирование — для защиты от логических ошибок и долгосрочного хранения.

##### Оптимальная стратегия — использовать оба подхода:

- Репликацию для минимального времени простоя

- Регулярные бэкапы для защиты от катастрофических сценариев

- Хранить бэкапы в нескольких географических локациях

- Регулярно тестировать восстановление как из реплик, так и из бэкапов